---
name: support_pipeline
description: Compose intent routing and response drafting into one support output.
version: 0.1.0
author: runllm
max_context_window: 12000
input_schema:
  type: object
  properties:
    ticket_text:
      type: string
    customer_tone:
      type: string
      enum: [calm, neutral, upset]
  required: [ticket_text, customer_tone]
  additionalProperties: false
output_schema:
  type: object
  properties:
    intent:
      type: string
      enum: [billing, technical, refund, sales, other]
    confidence:
      type: number
      minimum: 0
      maximum: 1
    reply:
      type: string
    urgency:
      type: string
      enum: [low, medium, high]
  required: [intent, confidence, reply, urgency]
  additionalProperties: false
llm:
  model: ollama/llama3.1:8b
llm_params:
  temperature: 0
  format: json
uses:
  - name: intent_router
    path: ./intent_router.rllm
    with:
      text: "{{input.ticket_text}}"
  - name: reply_drafter
    path: ./support_reply_drafter.rllm
    with:
      ticket_text: "{{input.ticket_text}}"
      intent: "{{uses.intent_router.intent}}"
      customer_tone: "{{input.customer_tone}}"
recommended_models:
  - ollama/llama3.1:8b
tags: [composition, support]
---
You are composing outputs from dependency apps.
Return ONLY JSON with keys: intent, confidence, reply, urgency.

Routing output:
intent={{uses.intent_router.intent}}
confidence={{uses.intent_router.confidence}}

Drafter output:
reply={{uses.reply_drafter.reply}}
urgency={{uses.reply_drafter.urgency}}
